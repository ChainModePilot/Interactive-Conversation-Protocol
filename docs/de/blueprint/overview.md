# Interactive Conversation Protocol

## 1. Projektdefinition

Interactive Conversation Protocol (ICP) ist ein strukturiertes Protokoll zur Beschreibung von Direktivbedeutungen. Clients k√∂nnen Direktivbedeutungen basierend auf der Struktur dieses Protokolls zu menschenerkennbaren modularen multimodalen Nachrichten kombinieren.

**Kernpositionierung**: Eine Zwischensprachform f√ºr die Mensch-Maschine-Interaktion, im Wesentlichen eine strukturierte Textdarstellung eines Konzeptgraphen, die wir "Conception Annotation" nennen.

## 2. Warum dieses Projekt erstellt wurde

### ‚ùì Zu l√∂sende Probleme

Wir m√ºssen der Realit√§t ins Auge sehen: F√ºr einen betr√§chtlichen Zeitraum wird bestimmt, wie mit Benutzern interagiert wird, von Endseiten-Entwicklern (oder Unternehmen). Unter den meisten bestehenden Gesch√§ftsmodellen ist die Beteiligung der Benutzer an der Interaktion die Grundlage des Produktwerts und der Rentabilit√§t, wie aktive Benutzerzahlen und Werbeeinnahmen. Niemand kann Endseiten zwingen, ausreichende Berechtigungen zu √∂ffnen und zuzulassen, dass KI Operationen vollst√§ndig ohne menschliches Eingreifen ausf√ºhrt.

Wenn KI intelligent genug ist, m√ºssen Menschen tats√§chlich nicht jedes Mal von der Startseite beginnen. Daher k√∂nnen wir sehen, dass der Mensch-Maschine-Dialog zur Hauptschnittstelle der n√§chsten Generation wird, was fast zu einem Konsens geworden ist.

Die nat√ºrlichen Defekte der nat√ºrlichen Sprachexpressivit√§t, die urspr√ºnglich hofften, durch gut gestaltete Interaktionen kompensiert zu werden, werden jedoch jetzt durch Dialogfelder ersetzt. Die Einschr√§nkungen von Dialogfeldern werden sofort offengelegt:

#### (1) Verlust der Indikationsfunktion des Cursors

Interaktionsformen verschieben sich vom Modus "Bildschirm + Fokus-Operation" zum nat√ºrlichen Sprachmodus. Traditionelle Fokus-Operationen werden √ºber Tastaturen, M√§use und Touchscreens erreicht und bieten pr√§zise Indikation. Die nat√ºrliche Sprachinteraktion bringt folgende Auswirkungen mit sich:

- **Verlust der indikativen Pr√§zision**: Die Schwierigkeit des Ausdrucks und Verstehens nimmt zu, und die Mehrdeutigkeit w√§chst, was wir den "Cursor-Verlust-Effekt" nennen.
  > Wenn ein Benutzer beispielsweise "l√∂sche dies" sagt, hat das System Schwierigkeiten zu bestimmen, auf welches spezifische Objekt sich "dies" bezieht, w√§hrend traditionelle Schnittstellen durch Mausklicks pr√§zise lokalisieren k√∂nnen.

- **Begrenzte Effizienz der Informationsausdr√ºcke**: Reine Sprachinformationsausdr√ºcke sind ineffizient, und der Vorteil der Spracheingabe zeigt sich haupts√§chlich in Wort-f√ºr-Wort-Ausdrucksszenarien.
  > Wenn Sie beispielsweise eine Miniaturansicht vergr√∂√üern m√∂chten, m√ºssen Sie m√∂glicherweise "vergr√∂√üern" sagen oder "vergr√∂√üern" tippen, w√§hrend die traditionelle Interaktion nur einen einzigen Klick erfordert.

- **Hohe Anforderungen an sprachliche Ausdrucksf√§higkeit**: Die nat√ºrliche Sprachinteraktion stellt hohe Anforderungen an die sprachliche Ausdrucksf√§higkeit der Benutzer und schafft Schwierigkeiten in der Mensch-Maschine-Interaktion.
  > Benutzer, die nicht gut in sprachlichem Ausdruck sind, k√∂nnen m√∂glicherweise ihre Bed√ºrfnisse nicht genau beschreiben, was zu Systemverst√§ndnisabweichungen f√ºhrt, w√§hrend traditionelle Schnittstellen die Ausdrucksschwelle durch visuelle Elemente wie Schaltfl√§chen und Men√ºs senken.

- **Niedrige Effizienz beim Informationslesen**: Textstromlesen und Sprachlesen sind weniger effizient als strukturiertes Informationslesen.
  > Wenn das System beispielsweise eine lange Datenliste per Sprache ausgibt, m√ºssen Benutzer die gesamte Liste anh√∂ren, um Zielinformationen zu finden, w√§hrend traditionelle Schnittstellen es Benutzern erm√∂glichen, durch strukturierte Formen wie Tabellen und Karten schnell zu scannen und zu lokalisieren.

- **Eingeschr√§nkt durch Dialogrunden**: Interaktionen, die durch Dialogrunden eingeschr√§nkt sind, sind nicht freundlich f√ºr schnelle kontinuierliche Operationen.
  > Wenn Benutzer mehrere Operationen kontinuierlich ausf√ºhren m√ºssen, m√ºssen sie warten, bis jede Dialogrunde abgeschlossen ist, bevor sie zum n√§chsten Schritt √ºbergehen k√∂nnen, w√§hrend traditionelle Schnittstellen mehrere Schaltfl√§chen schnell nacheinander klicken k√∂nnen, um Batch-Operationen abzuschlie√üen.

#### (2) Informationsfragmentierungs√ºberlauf

Die Streaming-Informationsstruktur von Gespr√§chen mangelt es an Organisation, anders als traditionelle Software, die Informationsarchitekturen in Seiteneinheiten organisiert und visuell freundliche Informationspr√§sentationshierarchien durch visuelle grafische Schnittstellen aufbaut. Dies f√ºhrt zu folgenden abgeleiteten Problemen:

- **Schwierigkeit, verschiedene Informationen zu isolieren**: Kontinuierliche Informationsfl√ºsse innerhalb eines einzelnen Gespr√§chs machen es schwierig, Grenzen zwischen verschiedenen Themen zu unterscheiden, und sogar mehrere v√∂llig unabh√§ngige Themen k√∂nnen miteinander vermischt werden.
  > Ein Benutzer fragt beispielsweise zuerst "hilf mir, das Wetter von morgen zu √ºberpr√ºfen" in einem Gespr√§ch, fragt dann "wie ist der Projektfortschritt", und fragt dann "empfehle einige gute B√ºcher". Diese v√∂llig unabh√§ngigen Themen sind miteinander vermischt, was es schwierig macht, schnell zu lokalisieren und zu √ºberpr√ºfen.

- **Zombie-Sitzungs-Explosion**: Wenn Informationen k√ºnstlich durch Sitzungen isoliert werden, werden Informationen innerhalb von Sitzungen in Blackboxen mit Sitzungen als Einheiten gefaltet und werden schlie√ülich zu Zombie-Sitzungen aufgrund niedriger Sichtbarkeit.
  > Benutzer erstellen beispielsweise mehrere Sitzungen wie "arbeitsbezogen", "Studiennotizen", "Einkaufsliste", aber jede Sitzung hat nur verstreute Nachrichten. Im Laufe der Zeit werden diese Sitzungen vergessen und werden zu Zombie-Sitzungen, die nicht effektiv genutzt werden k√∂nnen.

- **Nicht in der Lage, mehrdimensional zu verwalten**: √Ñhnliche Informationen, die √ºber unz√§hlige Sitzungen verstreut sind, k√∂nnen nicht organisiert werden, weil Informationen nicht entlang einer bestimmten Dimension verwaltet werden k√∂nnen.
  > Benutzer haben beispielsweise in verschiedenen Sitzungen nach "Python-Tutorial", "JavaScript-Tutorial", "React-Tutorial" und anderen Lernressourcen gefragt, k√∂nnen sie aber nicht einheitlich entlang der Dimension "Lernressourcen" anzeigen und verwalten und k√∂nnen nur Sitzung f√ºr Sitzung suchen.

- **Mangel an indizierbaren Objekten**: Informationen l√∂sen sich in Textinformationen auf, und wenn wir auf etwas verweisen m√ºssen, gibt es kein spezifisches Objekt, auf das verwiesen werden kann.
  > Wenn ein Benutzer beispielsweise sagt "optimieren Sie diesen Vorschlag erneut", ist "dieser Vorschlag" nur ein Absatz im Textstrom ohne unabh√§ngige Identifikation und Struktur, was es dem System erschwert, pr√§zise zu lokalisieren und zu operieren.

#### (3) Erhebliche Unterschiede in Mensch-Maschine-Schnittstellen √ºber verschiedene Terminals

Mehr Terminalger√§te in der Zukunft werden von Agents angetrieben, entsprechen der menschlichen Wahrnehmung durch Bildschirme, Kameras, Mikrofone, Lautsprecher und andere Ger√§te, um Mensch-Maschine-Interaktionen abzuschlie√üen. Verschiedene Terminals haben jedoch inh√§rente Unterschiede in ihren physischen Eigenschaften, und es ist unm√∂glich, denselben Interaktionsmodus zwangsweise zu verwenden. Dies schafft Schwierigkeiten bei der KI-Integration:

- **Medientrennung**: Wenn die von KI zur√ºckgegebene Informationsstruktur terminalsunfreundlich ist, f√ºhrt dies unweigerlich zu Verlust oder Verwirrung bei der Informationsausdr√ºcke. Umgekehrt ist die von Terminals bereitgestellte Informationsstruktur nicht unbedingt KI-freundlich.
  > Eine komplexe Datenvisualisierung, die urspr√ºnglich f√ºr ein Gro√übildschirm-Dashboard designed wurde, wird beispielsweise direkt "vorgelesen" durch Sprache auf einem intelligenten Lautsprecher, was es Benutzern fast unm√∂glich macht, ein Gesamtverst√§ndnis zu entwickeln; umgekehrt kann eine einzelne Zeile von Prompt-Informationen auf einer Smartwatch kaum die komplexen Semantiken vollst√§ndig tragen, die KI auszudr√ºcken erwartet.

- **KI beherrscht Terminaleigenschaften nicht**: Um die Ausdruckskraft zu verbessern, verwenden Menschen oft mehrere Software und Terminals, um in komplexen Kontexten oder beim Ausdr√ºcken komplexer Logik zu demonstrieren. KI scheint nur zu wissen, wie man "spricht".
  > Wenn ein Produktmanager beispielsweise einen Vorschlag pr√§sentiert, zeigen sie Folien, zeichnen Strukturdiagramme auf einem Whiteboard und klicken Operationen auf Demo-Seiten; w√§hrend aktuelle KI oft nur mit einem langen Text oder einer Sprachfolge erkl√§ren kann, was es schwierig macht, Terminalf√§higkeiten wie Projektion, Annotation und Animation zu verwenden, um die Ausdruckskraft zu verbessern.

- **L√ºcke zwischen Virtual und Realit√§t**: Der Kontext (oder Kontext), der derzeit von KI verwendet wird, basiert auf voreingestelltem und auswendig gelerntem Wissen, w√§hrend der Kontext in realen Szenarien oft dynamisch und mit der realen Umgebung verbunden ist.
  > KI kann beispielsweise "sich erinnern" an pers√∂nliche Profile und historische Gespr√§che der Benutzer, aber es ist schwierig, in Echtzeit wahrzunehmen, dass der Benutzer in einem Konferenzraum sitzt, durch welche Seite eines Papierdokuments bl√§ttert oder auf welches physische Display-Board zeigt, und kann daher keine nat√ºrlichen Anweisungen und Erg√§nzungen basierend auf Situationen vor Ort wie ein echter Assistent machen.

### üí° Verbesserungsideen und Ziele

Zuvor war die Hauptarbeit von Produktmanagern das Design von leicht zu erlernenden und leicht zu verwendenden Schnittstellen und Betriebsabl√§ufen. Mit KI-Unterst√ºtzung m√ºssen Benutzer nicht mehr Software-Interaktionsschnittstellen und Betriebslogik lernen. KI hat die F√§higkeit, Benutzern nur notwendige Informationen basierend auf Benutzerfragen und Anweisungen bereitzustellen, und Benutzer ben√∂tigen nur minimale Eingriffsoperationen.

Solange Benutzer selbst eingreifen, gibt es jedoch Probleme mit Interaktionsfreundlichkeit, Genauigkeit und Effizienz. Interactive Conversation Protocol spielt genau am Punkt des Mensch-Maschine-Kontakts eine Rolle:

#### Verbesserung der Ausdruckskraft der nat√ºrlichen Sprache (Mensch ‚Üí KI)

Die Verbesserung der Ausdruckskraft bezieht sich hier auf die Verbesserung der nat√ºrlichen Sprache. Um die oben erw√§hnten Probleme zu kompensieren (Verlust der Cursor-Indikation, Informationsfragmentierungs√ºberlauf und Unterschiede in Mensch-Maschine-Schnittstellen √ºber verschiedene Terminals). Zumindest kann die folgende Verarbeitung an urspr√ºnglicher nat√ºrlicher Sprache durchgef√ºhrt werden:

- **Markieren ausgedr√ºckter Informationen**: Markieren Sie Informationen, die eine spezielle Verarbeitung ben√∂tigen. Die hier erw√§hnte spezielle Verarbeitung umfasst die Verwendung strukturierter Informationen, das Zusammenstellen von Schnittstellen, das Ausf√ºhren von Hilfsprogrammen usw. Sie k√∂nnen sich das vorstellen, als w√ºrden Sie Notizen machen, indem Sie Punkte auf einem Textst√ºck umkreisen. In Bezug auf die Markierungsform beziehen wir uns auf Markdown, verwenden spezielle Zeichen, um spezifische Bedeutungen darzustellen, w√§hrend die Erkl√§rung und Ausl√∂sung von Hilfsfunktionen sich auf das Annotationsprinzip in der Java-Entwicklung bezieht. Durch diese Methode k√∂nnen wir den Ton der Sprache erg√§nzen, darauf hinweisen, was wichtig ist, was spezielle Pr√§sentationsformen ben√∂tigt und was Voroperationen ben√∂tigt (wie Authentifizierung, die nur f√ºr sich selbst sichtbar ist) im urspr√ºnglichen expository Inhalt.
  > Wenn ein Benutzer beispielsweise sagt "hilf mir, die To-dos dieser Woche zu organisieren", markieren Sie Daten, Priorit√§ten und verantwortliche Personen leicht im Satz, kann KI direkt eine √ºberpr√ºfbare To-do-Liste generieren, anstatt nur einen beschreibenden Text zur√ºckzugeben.

- **Hinzuf√ºgen von Kontextinformationen**: Erg√§nzen Sie notwendige virtuelle Informationen und reale Umgebung in die narrative Information, um die reale Situation des Sprechers zu reproduzieren. Traditionelle Interaktionsschnittstellen stellen oft optionale Kontextinformationen in der Schnittstelle bereit, um genaue Absichten der Benutzer aus einfachen Klicks zu erfassen, w√§hrend nat√ºrliche Sprache umfangreiche Texte organisieren muss, um den Kontext vollst√§ndig zu beschreiben. Durch Erg√§nzen von Kontextinformationen wie Zeit, Ort, Ger√§testatus und Teilnehmeridentit√§t im Protokoll kann KI die echten Semantiken von "hier und jetzt" genauer verstehen.
  > Wenn ein Benutzer beispielsweise nur sagt "buchen Sie ein Restaurant, das Marry in der N√§he mag", erg√§nzen Sie Standort, Budgetpr√§ferenzen und historische Bestellungen als Kontextinformationen. Die Anwendung von Kontextinformationen ist sehr breit, und wir werden Szenarien sp√§ter speziell diskutieren.

- **√úbersetzen in Standard-Zwischensprache**: Nach der Verarbeitung urspr√ºnglicher Informationen (Hinzuf√ºgen von Anmerkungen und Kontextinformationen), um eine vollst√§ndige und genaue Interpretation zu erm√∂glichen, ist ein vereinbartes Datenidentifikationssystem erforderlich. Um sich an die Ausdruckskraft aller Terminals anzupassen, kann dieses Identifikationssystem auf JSON-Spezifikationen aufgebaut werden und vereinbarte Parametertabellen und Strukturen bereitstellen. Auf diese Weise k√∂nnen KIs an verschiedenen Empfangsenden alle verf√ºgbaren Terminals mobilisieren, um maximale Ausdruckskraft zu zeigen und die vollst√§ndige Bedeutung des Ausdr√ºckers zu reproduzieren.
  > Ein Satz "senden Sie diesen Absatz an die Projektgruppe und lassen Sie alle vor Arbeitsende heute best√§tigen" wird beispielsweise letztendlich in eine Standard-JSON-Struktur √ºbersetzt, die Nachrichtenk√∂rper, Empf√§ngerliste, Frist und Best√§tigungstastenkonfiguration enth√§lt. Chat-Tools, Web-Backends oder mobile Apps k√∂nnen alle ihre jeweiligen angepassten Schnittstellen entsprechend rendern.

#### On-Demand-Angepasste Schnittstelle (KI ‚Üí Mensch)

Unsere Pr√§misse ist, dass Menschen es vorziehen werden, mit KI durch "Sprechen" zu interagieren, was der menschlichen Kommunikation am n√§chsten kommt. Daher werden Menschen es zunehmend zu l√§stig finden, die ben√∂tigten Funktionsschnittstellen durch Klicken zu finden. Die Informationen und Schnittstellen, die Menschen ben√∂tigen, sollten direkt zu den "Augen" der Benutzer gepusht werden. Um diesen Effekt zu erzielen, sollten Empfangsenden bestimmte Interpretationsf√§higkeiten haben:

- **Interpretieren der Zwischensprache**: Da die Zwischensprache im JSON-Format ist, k√∂nnen alle Empfangsenden vollst√§ndige Semantiken lesen und zumindest eine Trennung bei der Informationsempfang vermeiden.
  > Die gleichen Zwischensprachdaten einer "Spesenabrechnungspr√ºfanfrage" k√∂nnen beispielsweise als Gro√übildschirmschnittstelle mit Tabellen und Anhangsvorschau auf dem Desktop gerendert werden, zeigen nur wichtige Informationen und zwei Tasten (genehmigen/ablehnen) auf dem Mobilger√§t, w√§hrend intelligente Lautsprecher Zusammenfassungen vorlesen und auf Sprachbest√§tigung warten k√∂nnen.

- **Dynamisches Konstruieren von Nachrichtenschnittstellen**: Basierend auf vollst√§ndigem Kontext und Anmerkungen w√§hlen Sie die interaktionsfreundlichste L√∂sung und setzen dynamisch eine interaktive Schnittstelle mit Informationshierarchie zusammen (nat√ºrlich k√∂nnen auch mit Terminals inkompatible Anmerkungen ignoriert werden). Diese Schnittstelle ist nicht unbedingt schreibgesch√ºtzte multimodale Information, kann aber auch ein interaktiver Mini-Programmk√∂rper sein.
  > Wenn KI beispielsweise versteht "dies ist eine Informationssammlung", kann es automatisch eine ausf√ºllbare kleine Formularkarte in der Chat-Schnittstelle einf√ºgen, anstatt Benutzer zu haben, die Fragen nacheinander in Klartext beantworten.

- **Reproduzieren des Kontexts**: Haben Sie die F√§higkeit, einige Elemente im Kontext anzuzeigen oder zu steuern. Dies erfordert normalerweise die Mobilisierung mehrerer Anwendungen oder Terminalger√§te. Wir haben gesehen, dass die Perspektive der ersten Person durch Kameras auf Brillen reproduziert werden kann, die Perspektive der dritten Person von Begleitdrohnen bedient werden kann und Projektion oder VR-Symbole auf eine bestimmte Position an physischen Objekten zeigen k√∂nnen... und so weiter.
  > In einem Szenario der Fernwartung von Ger√§ten kann KI beispielsweise die Position von Schrauben, die demontiert werden m√ºssen, im AR-Sichtfeld des Ingenieurs hervorheben, w√§hrend gleichzeitig Schaltkreisdiagramme und Schrittanweisungen auf einem Gro√übildschirm angezeigt werden, wodurch "Kontext" gemeinsam √ºber mehrere Terminals reproduziert werden kann.

#### ‚ùóÔ∏è‚ùóÔ∏è Besonderer Hinweis: Ist Zwischensprache wirklich notwendig?

Viele Menschen denken, dass Zwischensprache tats√§chlich nicht ben√∂tigt wird, im Allgemeinen aus zwei Gr√ºnden:

(1) Langfristig hat AGI die F√§higkeit, "zwischen den Zeilen zu lesen" und die impliziten Absichten der Benutzer zu verstehen. Es ist nicht notwendig, nat√ºrliche Sprache k√ºnstlich unn√∂tig zu verarbeiten, nur um KI zu helfen, besser zu verstehen.

(2) Das Design menschfreundlicher Interaktionsschnittstellen ist auch AGIs Pflicht in der Zukunft, und KI kann sogar eine lauff√§hige Interaktionsschnittstelle speziell f√ºr jede Interaktion entwerfen. Daher ist es noch unn√∂tiger, KIs Worte in eine Zwischensprache zu √ºbersetzen.

Wir haben letztendlich immer noch das ICP-Protokoll im iFay-System entworfen. Wir haben die folgenden 3 Bedenken und glauben, dass sie kurzfristig schwer zu l√∂sen sind, daher haben wir uns entschieden, eine Annotationsstil-Zwischensprache zu entwerfen:

(1) KIs Kontrolle √ºber die Umgebung ist nicht so gro√ü

Im Allgemeinen vergleichen Menschen Mensch-KI-Interaktionen mit der Kommunikation zwischen einer Person und einem Assistenten. Sie denken, dass ein intelligenter Assistent aktiv Umgebungsbedingungen anpassen wird, um gute Kommunikationseffekte zu erzielen, wie z. B. Lichter einschalten, wenn nicht genug Licht vorhanden ist; Markierungen an wichtigen Stellen von Dokumenten machen. Aber die Berechtigungen und F√§higkeiten von Assistenten erlauben es ihnen nicht immer, alles zu tun, wie z. B. wenn ein Geb√§ude pl√∂tzlich Strom verliert und Pr√§sentationsfolien nicht abgespielt werden k√∂nnen.

Daher ist ein vorsichtigerer Ansatz, alle notwendigen Materialien vorzubereiten und die Pr√§sentation anzupassen (oder sie dem Hausmeister zu √ºberlassen). Dies ist, als w√ºrde man alle Materialien mitbringen, um einen Kunden zu treffen. Ob der Kunde einen Konferenzraum hat, ob Pr√§sentationsfolien abgespielt werden k√∂nnen oder ob Papierberichte angesehen werden m√ºssen, wird von der anderen Partei entschieden.

(2) KI und Menschen sind m√∂glicherweise nicht so nah

Da KIs Kontrolle √ºber die Umgebung begrenzt ist, versteht KI tats√§chlich in vielen F√§llen die menschliche Bedeutung nicht wirklich. Es ist, als w√ºrde man auf einen Datensatz auf einer Folie zeigen und KI fragen: "Was bedeutet diese Daten?" Tats√§chlich wei√ü KI nicht, wo Sie zeigen. Idealerweise w√§ren Bewegungsaufzeichnungsger√§te erforderlich, um KI diese Information mitzuteilen. Sie k√∂nnen sich auch ein anderes Szenario vorstellen: Ein Boss h√§lt eine geschlossene Sitzung ab und sagt dem Assistenten danach: "Folgen Sie den Sitzungsbeschl√ºssen nach." Zu diesem Zeitpunkt hat der Assistent tats√§chlich keine Informationen aus erster Hand erhalten, sondern Sitzungsprotokolle, die von einem Sitzungsprotokollf√ºhrer organisiert wurden. Sitzungsprotokolle √§hneln Informationen, die von Zwischensprache verarbeitet wurden.

Daher reichen in vielen F√§llen die von Menschen explizit bereitgestellten Informationen nicht aus, um zu urteilen. Zu diesem Zeitpunkt m√ºssen Kontextinformationen erg√§nzt werden, aber dies ist nicht die Autorit√§t einer bestimmten KI.

(3) Es gibt m√∂glicherweise √ºberhaupt keine universelle AGI

Zuk√ºnftige KI wird definitiv auf die gleichen Arbeitsteilungsprobleme sto√üen wie die menschliche Gesellschaft. Es wird individuelle KIs (√§hnlich wie iFay) und KIs mit sozialen √∂ffentlichen Funktionen (√§hnlich wie coFay) geben. Zwischen ihnen wird es zwangsl√§ufig Berechtigungsgrenzen geben.

Es ist schwierig f√ºr uns vorherzusagen, ob in der zuk√ºnftigen KI-√ñkosystem die Verantwortung von KI nur darin besteht, bereitgestellte (Systemeingabe-)Informationen zu verarbeiten, oder ob KI auch daf√ºr verantwortlich sein sollte, aktiv mehr "Implikationen" zu sammeln.

Daher w√§hlen wir einen vorsichtigen Ansatz. Wir nehmen an, dass KI nur bekannte Informationen verarbeitet. Es ist nur so, dass diese Informationen jedes Mal durch einen Verarbeitungsfluss gehen, und diese Verarbeitungsaktion kann von einer Software, einem Terminalger√§t oder einer KI abgeschlossen werden. Dies ist auch eine sehr reife Praxis in aktuellen technischen L√∂sungen, wie z. B. die Verwendung eines Browsers zum Zugriff auf eine Website, bei der der Server einen Teil der Kontextinformationen des Benutzers erfahren kann.

### üåü Vision

ICP (Interactive Conversation Protocol) zielt darauf ab, eine Zwischensprachform zwischen Menschen und Maschinen aufzubauen und eine effiziente, genaue und reichhaltige bidirektionale Kommunikation zwischen Menschen und Maschinen zu erreichen:

#### Mensch ‚Üí Maschine: Umfassende Replikation von ausgedr√ºckter Bedeutung und Kontext

- Die Bedeutung und den Kontext, die von Menschen ausgedr√ºckt werden, so umfassend wie m√∂glich erfassen
- Nat√ºrliche Sprache und Interaktionsabsichten in strukturierte Elemente umwandeln, die Maschinen genau verstehen k√∂nnen
- Interaktionspr√§zision und Kontextinformationen bewahren

#### Maschine ‚Üí Mensch: Dynamische Zusammenstellung von Interaktionsmethoden

- Konzeptanmerkungen mit dem aktuellen Kontext integrieren
- Basierend auf Ger√§tef√§higkeiten und Benutzerpr√§ferenzen die am besten geeigneten Interaktionsmethoden dynamisch zusammenstellen
- Multi-perzeptive Informationspr√§sentation unterst√ºtzen (Text, Stimme, Vision, Ber√ºhrung, Geruch usw.)

